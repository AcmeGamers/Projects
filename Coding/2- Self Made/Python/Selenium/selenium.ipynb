{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium Automation\n",
    "A script that uses Selenium to automate scrapping data from a specific website. Note, you will need to run the script in adminstration mode because the temporary directory cannot be created in the user mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['PIN', 'Physical Address','Unit','City','Zip Code','Descriptive Location','Neighborhood','Class','Land Use Code','Acres','Land Type','Frontage Width and Depth','Street1/Street2','Topo1/Topo2/Topo3','Util1/Util2/Util3','Restrict1/Restrict2/Restrict3']\n",
    "url = 'https://taxdata.nashcountync.gov/search/commonsearch.aspx?mode=parid'\n",
    "searchBarName = 'inpParid'\n",
    "key = '023823'\n",
    "keys = ['023823', '023824', '023825', '023826', '023827', '023828', '023829', '023830', '023831', '023832', '023833', '023834', '023835', '023836', '023837', '023838', '023839', '023840', '023841', '023842', '023843', '023844', '023845', '023846', '023847', '023848', '023849', '023850', '023851', '023852', '023853', '023854', '023855', '023856', '023857', '023858', '023859', '023860', '023861', '023862', '023863', '023864', '023865', '023866', '023867', '023868', '023869', '023870', '023871', '023872', '023873', '023874', '023875', '023876', '023877', '023878', '023879', '023880', '023881', '023882', '023883', '023884', '023885', '023886', '023887', '023888', '023889', '023890', '023891', '023892', '023893', '023894', '023895', '023896', '023897', '023898', '023899', '023900', '023901', '023902', '023903', '023904', '023905', '023906', '023907', '023908', '023909', '023910', '023911', '023912', '023913', '023914', '023915', '023916', '023917', '023918', '023919', '023920', '023921', '023922', '023923', '023924', '023925', '023926', '023927',]\n",
    "elementToGet = 'PARCEL'\n",
    "resultsArray = []\n",
    "resultFile = 'results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singlePackage(url, searchBarName, key='023823'):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    searchBar = driver.find_element(By.NAME, value=searchBarName)\n",
    "    searchBar.send_keys(key)\n",
    "    searchBar.send_keys(Keys.RETURN)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    wait.until(lambda driver: driver.find_element(By.NAME, value=elementToGet)) \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.find_all('table', {'id': 'Parcel'})\n",
    "\n",
    "    rows = results[0].find_all('tr')\n",
    "    col =  rows[0].find_all('td')\n",
    "\n",
    "    with open(resultFile, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(headers)\n",
    "        result = []\n",
    "        try:\n",
    "            for row in rows:\n",
    "                col = row.find_all('td')\n",
    "                col = col[1].text.split(',')\n",
    "                for c in col:\n",
    "                    result.append(c.strip())                          \n",
    "        except IndexError:\n",
    "            print('IndexError')\n",
    "        \n",
    "        writer.writerow(result)  \n",
    "            \n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplePackages(url, searchBarName, keys):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    for key in keys:\n",
    "        searchBar = driver.find_element(By.NAME, value=searchBarName)\n",
    "        searchBar.send_keys(key)\n",
    "        searchBar.send_keys(Keys.RETURN)\n",
    "        wait = WebDriverWait(driver, 10) \n",
    "        wait.until(lambda driver: driver.find_element(By.NAME, value=elementToGet))\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        results = soup.find_all('table', {'id': 'Parcel'})\n",
    "        rows = results[0].find_all('tr')\n",
    "        col =  rows[0].find_all('td')\n",
    "        with open(resultFile, 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            result = []\n",
    "            try:\n",
    "                for row in rows:\n",
    "                    col = row.find_all('td')\n",
    "                    col = col[1].text.split(',')\n",
    "                    for c in col:\n",
    "                        result.append(c.strip()) \n",
    "            except IndexError:\n",
    "                print('IndexError')\n",
    "            writer.writerow(result)\n",
    "             \n",
    "        driver.get(url)\n",
    "             \n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singlePackage(url, searchBarName, key)\n",
    "# multiplePackages(url, searchBarName, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves CSV file\n",
    "import csv\n",
    "with open('results.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    writer.writerows(resultsArray)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9fdc8b38eeb13e23080d8401b889c3fdc15778a64593e63aa6185e4d38c6371"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
